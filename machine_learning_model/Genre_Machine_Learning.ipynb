{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- SQL_Connection to local Postgres SQL Database\n",
    "\n",
    "# Resources for connection help:\n",
    "# -- https://medium.com/analytics-vidhya/postgresql-integration-with-jupyter-notebook-deb97579a38d\n",
    "# -- https://overiq.com/sqlalchemy-101/installing-sqlalchemy-and-connecting-to-database/\n",
    "\n",
    "# Load ipython-sql to use and store SQL commands in notebook\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Import connection string from config file\n",
    "from config import db_password\n",
    "from config import port_number \n",
    "from config import db_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Engine(postgres://postgres:***@localhost:5433/SteamDB)\n"
    }
   ],
   "source": [
    "# Connect sqlalchemy to database using connection string\n",
    "\n",
    "db_string = f\"postgres://postgres:{db_password}@localhost:{port_number}/{db_name}\"\n",
    "\n",
    "# -- Alternate db_string for engine connection, update host and DB connection as needed. \n",
    "# db_string = f\"postgres://postgres:{db_password}@127.0.0.1:54642/SteamDB\"\n",
    "\n",
    "engine = create_engine(db_string)\n",
    "\n",
    "print(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                   game_name  percent_positive_reviews   genre  action  \\\n0             COUNTER-STRIKE                      97.0  Action    True   \n1      TEAM FORTRESS CLASSIC                      84.0  Action    True   \n2              DAY OF DEFEAT                      90.0  Action    True   \n3         DEATHMATCH CLASSIC                      83.0  Action    True   \n4  HALF-LIFE: OPPOSING FORCE                      95.0  Action    True   \n\n   adventure  casual  design_and_illustration  early_access  free_to_play  \\\n0      False   False                    False         False         False   \n1      False   False                    False         False         False   \n2      False   False                    False         False         False   \n3      False   False                    False         False         False   \n4      False   False                    False         False         False   \n\n   indie  massively_multiplayer    rpg  racing  simulation  sports  strategy  \\\n0  False                  False  False   False       False   False     False   \n1  False                  False  False   False       False   False     False   \n2  False                  False  False   False       False   False     False   \n3  False                  False  False   False       False   False     False   \n4  False                  False  False   False       False   False     False   \n\n   utilities  \n0      False  \n1      False  \n2      False  \n3      False  \n4      False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>game_name</th>\n      <th>percent_positive_reviews</th>\n      <th>genre</th>\n      <th>action</th>\n      <th>adventure</th>\n      <th>casual</th>\n      <th>design_and_illustration</th>\n      <th>early_access</th>\n      <th>free_to_play</th>\n      <th>indie</th>\n      <th>massively_multiplayer</th>\n      <th>rpg</th>\n      <th>racing</th>\n      <th>simulation</th>\n      <th>sports</th>\n      <th>strategy</th>\n      <th>utilities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>COUNTER-STRIKE</td>\n      <td>97.0</td>\n      <td>Action</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TEAM FORTRESS CLASSIC</td>\n      <td>84.0</td>\n      <td>Action</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DAY OF DEFEAT</td>\n      <td>90.0</td>\n      <td>Action</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DEATHMATCH CLASSIC</td>\n      <td>83.0</td>\n      <td>Action</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HALF-LIFE: OPPOSING FORCE</td>\n      <td>95.0</td>\n      <td>Action</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Create Game Genre dataframe from SQL table \n",
    "\n",
    "genre_df = pd.read_sql('SELECT * FROM gamegenres', engine)\n",
    "\n",
    "genre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins as 0 to 80 for unpopular, 80 - 100 as popular\n",
    "bins = [0,75,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = unpopular, 1 = popular\n",
    "group_names = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut the data based on the percent_positive_reviews and bin them into a column named classification\n",
    "genre_df['classification'] = pd.cut(genre_df['percent_positive_reviews'], bins, labels = group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1    4210\n0    1977\nName: classification, dtype: int64"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# 1977 games were classified as unpopular and 4210 games were classified as popular\n",
    "genre_df['classification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the columns that have strings\n",
    "genre_df = genre_df.drop(['game_name', 'percent_positive_reviews', 'genre'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separate the Features (X) from the Target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = genre_df['classification']\n",
    "X = genre_df.drop(columns='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Split our data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(4640, 14)"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=200,\n",
    "                                random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit (train) or model using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LogisticRegression(max_iter=200, random_state=1)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    Prediction Actual\n0            1      0\n1            1      0\n2            1      1\n3            1      1\n4            1      1\n5            1      0\n6            1      1\n7            1      1\n8            1      1\n9            1      1\n10           1      1\n11           1      1\n12           1      0\n13           1      1\n14           1      1\n15           1      1\n16           1      1\n17           1      0\n18           1      0\n19           1      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Prediction</th>\n      <th>Actual</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.7045895281189399\n"
    }
   ],
   "source": [
    "# Predict Accuracy Score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The logistic regression model gave us an accuracy score of about 70% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[  64  430]\n [  27 1026]]\n"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n           0       0.70      0.13      0.22       494\n           1       0.70      0.97      0.82      1053\n\n    accuracy                           0.70      1547\n   macro avg       0.70      0.55      0.52      1547\nweighted avg       0.70      0.70      0.63      1547\n\n"
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## According to the classification report, the precision of the mahcine learning model was roughly 70% for predicting both popular games and unpopular games via genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The next test we decided to run was the Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from path import Path \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   action  adventure  casual  design_and_illustration  early_access  \\\n0    True      False   False                    False         False   \n1    True      False   False                    False         False   \n2    True      False   False                    False         False   \n3    True      False   False                    False         False   \n4    True      False   False                    False         False   \n\n   free_to_play  indie  massively_multiplayer    rpg  racing  simulation  \\\n0         False  False                  False  False   False       False   \n1         False  False                  False  False   False       False   \n2         False  False                  False  False   False       False   \n3         False  False                  False  False   False       False   \n4         False  False                  False  False   False       False   \n\n   sports  strategy  utilities  \n0   False     False      False  \n1   False     False      False  \n2   False     False      False  \n3   False     False      False  \n4   False     False      False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>action</th>\n      <th>adventure</th>\n      <th>casual</th>\n      <th>design_and_illustration</th>\n      <th>early_access</th>\n      <th>free_to_play</th>\n      <th>indie</th>\n      <th>massively_multiplayer</th>\n      <th>rpg</th>\n      <th>racing</th>\n      <th>simulation</th>\n      <th>sports</th>\n      <th>strategy</th>\n      <th>utilities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# Define the features set.\n",
    "X = genre_df.copy()\n",
    "X = X.drop(\"classification\", axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[1, 1, 1, 1, 1]\nCategories (2, int64): [0 < 1]"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# Define the target set.\n",
    "y = genre_df[\"classification\"].values\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Data into Training and Testing Sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(4640, 14)\n(1547, 14)\n(4640,)\n(1547,)\n"
    }
   ],
   "source": [
    "# Determine the shape of our training and testing sets.\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Train and Test sets into an 80/20 split.\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, random_state=78, train_size=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(4949, 14)\n(1238, 14)\n(4949,)\n(1238,)\n"
    }
   ],
   "source": [
    "# Determine the shape of our training and testing sets.\n",
    "print(X_train2.shape)\n",
    "print(X_test2.shape)\n",
    "print(y_train2.shape)\n",
    "print(y_test2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a StandardScaler instance.\n",
    "scaler = StandardScaler()\n",
    "# Fitting the Standard Scaler with the training data.\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling the data.\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "# Creating the decision tree classifier instance.\n",
    "model = tree.DecisionTreeClassifier()\n",
    "# Fitting the model.\n",
    "model = model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data.\n",
    "predictions = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          Predicted 0  Predicted 1\nActual 0          113          379\nActual 1          120          935",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Predicted 0</th>\n      <th>Predicted 1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Actual 0</th>\n      <td>113</td>\n      <td>379</td>\n    </tr>\n    <tr>\n      <th>Actual 1</th>\n      <td>120</td>\n      <td>935</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuracy score.\n",
    "acc_score = accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6774402068519716"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Confusion Matrix\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "          Predicted 0  Predicted 1\nActual 0          113          379\nActual 1          120          935",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Predicted 0</th>\n      <th>Predicted 1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Actual 0</th>\n      <td>113</td>\n      <td>379</td>\n    </tr>\n    <tr>\n      <th>Actual 1</th>\n      <td>120</td>\n      <td>935</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy Score : 0.6774402068519716\nClassification Report\n              precision    recall  f1-score   support\n\n           0       0.48      0.23      0.31       492\n           1       0.71      0.89      0.79      1055\n\n    accuracy                           0.68      1547\n   macro avg       0.60      0.56      0.55      1547\nweighted avg       0.64      0.68      0.64      1547\n\n"
    }
   ],
   "source": [
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}